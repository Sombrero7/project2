{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# King County House Price Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![for sale image, from https://jpc-chicago.com/for-sale-signs-make-custom-real-estate-signs-and-sale-yard-sign/](images/forsale.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "---\n",
    "This project analyzes housing information drawn from the King County area from May 2014 to May 2015 in order to help Zillow determine an estimated price to post for new housing listings in that area. After the data were cleaned, normalized, and encoded, various iterative multiple linear regressions were run in order to converge on a model to use for the house price prediction. It was found that **results**, which led to **recommendations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Problem\n",
    "---\n",
    "Summary of the business problem you are trying to solve, and the data questions that you plan to answer to solve them.\n",
    "Questions to consider:\n",
    "Who are your stakeholders?\n",
    "What are your stakeholders' pain points related to this project?\n",
    "Why are your predictions important from a business perspective?\n",
    "\n",
    "In order to help Zillow improve their price estimations for King County, **results**. By following this model, it can help improve their estimation of prices for new houses in King County that need to be listed and can help customers get a more accurrate sense of which houses are in or out of their budget. This can help Zillow seem like a more reliable platform than other real estate listing sites, as being the first site to have information on the price of new listings can increase traffic and brand favorability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "\n",
    "Describe the data being used for this project.\n",
    "\n",
    "Questions to consider:\n",
    "\n",
    "- Where did the data come from, and how do they relate to the data analysis questions?\n",
    "- What do the data represent? Who is in the sample and what variables are included?\n",
    "- What is the target variable?\n",
    "- What are the properties of the variables you intend to use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here to explore your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Describe and justify the process for preparing the data for analysis.\n",
    "\n",
    "Questions to consider:\n",
    "\n",
    "- Were there variables you dropped or created?\n",
    "- How did you address missing values or outliers?\n",
    "- Why are these choices appropriate given the data and the business problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here to prepare your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First $&(@# Model\n",
    "\n",
    "Before going too far down the data preparation rabbit hole, be sure to check your work against a first 'substandard' model!\n",
    "\n",
    "At this point, you can also consider what a baseline, model-less prediction might look like, and begin evaluating this model compared to that baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here for your first 'substandard' model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "Describe and justify the process for analyzing or modeling the data.\n",
    "\n",
    "Questions to consider:\n",
    "\n",
    "- How did you analyze or model the data?\n",
    "- How did you iterate on your initial approach to make it better?\n",
    "- Why are these choices appropriate given the data and the business problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here to do your second, more refined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here to iteratively improve your models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Evaluate how well your work solves the stated business problem.\n",
    "\n",
    "Questions to consider:\n",
    "\n",
    "- How do you interpret the results?\n",
    "- How well does your model fit your data? How much better is this than your baseline model?\n",
    "- How well does your model/data fit any modeling assumptions?\n",
    "- How confident are you that your results would generalize beyond the data you have?\n",
    "- How confident are you that this model would benefit the business if put into use?\n",
    "\n",
    "Please note - you should be evaluating each model as you move through, and be sure to evaluate your models consistently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Provide your conclusions about the work you've done, including any limitations or next steps.\n",
    "\n",
    "Questions to consider:\n",
    "\n",
    "- What would you recommend the business do as a result of this work?\n",
    "- What are some reasons why your analysis might not fully solve the business problem?\n",
    "- What else could you do in the future to improve this project (future work)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.linear_model import Ridge\n",
    "from yellowbrick.datasets import load_concrete\n",
    "from yellowbrick.regressor import ResidualsPlot\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import stats\n",
    "\n",
    "def model_maker(X, y):\n",
    "    #Gets figures ready for plotting\n",
    "    fig, axes = plt.subplots(nrows = 2, figsize = (12,12))\n",
    "    \n",
    "    #Splits data in testing and training for evaluation\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=69)\n",
    "    \n",
    "    #ADD BACK IN IF NEED, SHOULD DO BEFORE CALLING\n",
    "#     Tests for Linearity/Multicollinearity\n",
    "#     print('Testing for Linearity and Multicollinearity')\n",
    "#     combine = pd.concat([X, y], axis = 1)\n",
    "#     sns.heatmap(abs(combine.corr()), annot = True)\n",
    "#     plt.show()\n",
    "    \n",
    "    #Makes model\n",
    "    X_const = sm.add_constant(X_train)\n",
    "    linreg_model = sm.OLS(y_train, X_train).fit()\n",
    "    \n",
    "    #Grabs predictions\n",
    "    train_predict = linreg_model.predict(X_train)\n",
    "    test_predict = linreg_model.predict(X_test)\n",
    "    \n",
    "    #Prints R^2\n",
    "    print(\"Model R2: \" + str(linreg_model.rsquared_adj))\n",
    "    \n",
    "    #Prints MSE\n",
    "    print(\"Train MSE: \" + str(mean_squared_error(y_train, train_predict)))\n",
    "    print(\"Test MSE: \" + str(mean_squared_error(y_test, test_predict)))\n",
    "    \n",
    "    #Creates residuals\n",
    "    train_resid = y_train - train_predict\n",
    "    test_resid = y_test - test_predict\n",
    "    \n",
    "    #Test for normality\n",
    "    print('Test for Normality')\n",
    "    sm.qqplot(train_resid, line = 'r', ax = axes[0])\n",
    "    #Also check JB value in model summary (<6)\n",
    "    \n",
    "    #Test for Heteroskedasticity\n",
    "    plt.scatter(train_predict, train_resid, label = 'Train')\n",
    "    plt.scatter(test_predict, test_resid, label='Test')\n",
    "    plt.axhline(y=0, color = 'red')\n",
    "    plt.xlabel('Predictions')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "     \n",
    "    return linreg_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
